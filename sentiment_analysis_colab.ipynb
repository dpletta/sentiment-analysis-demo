{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# \ud83c\udfe5 HIPAA-Compliant Sentiment Analysis Demo - Google Colab Version\n",
    "\n",
    "## Complete Self-Contained Analysis with AI Assistant\n",
    "\n",
    "This notebook is designed for Google Colab and includes:\n",
    "- \u2705 **Complete sentiment analysis code** (no external dependencies)\n",
    "- \u2705 **Synthetic healthcare data generation**\n",
    "- \u2705 **Service combination analysis**\n",
    "- \u2705 **Rich visualizations**\n",
    "- \u2705 **Hugging Face AI assistant** for result interpretation\n",
    "\n",
    "**Ready to run in Google Colab!** \ud83d\ude80"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Install Required Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages for Google Colab\n",
    "!pip install transformers torch nltk scikit-learn plotly seaborn\n",
    "\n",
    "print(\"\u2705 All packages installed successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Complete Sentiment Analysis System for Google Colab\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "import random\n",
    "from datetime import datetime, timedelta\n",
    "from collections import Counter, defaultdict\n",
    "import re\n",
    "from pathlib import Path\n",
    "\n",
    "# NLP libraries\n",
    "import nltk\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "# ML libraries\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import LatentDirichletAllocation, PCA\n",
    "from sklearn.metrics import silhouette_score\n",
    "\n",
    "# Visualization\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "# Download NLTK data\n",
    "try:\n",
    "    nltk.download(\"vader_lexicon\", quiet=True)\n",
    "    nltk.download(\"stopwords\", quiet=True)\n",
    "    nltk.download(\"punkt\", quiet=True)\n",
    "    nltk.download(\"wordnet\", quiet=True)\n",
    "except:\n",
    "    pass\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "plt.style.use(\"default\")\n",
    "\n",
    "class HealthcareSentimentAnalyzer:\n",
    "    \"\"\"\n",
    "    Complete sentiment analysis system for healthcare feedback.\n",
    "    Designed for Google Colab with all dependencies included.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.sia = SentimentIntensityAnalyzer()\n",
    "        self.lemmatizer = WordNetLemmatizer()\n",
    "        self.stop_words = set(stopwords.words(\"english\"))\n",
    "        self.tfidf_vectorizer = None\n",
    "        self.kmeans_model = None\n",
    "        self.lda_model = None\n",
    "        self.data = None\n",
    "        self.analyzed_data = None\n",
    "        self.combinations = []\n",
    "        \n",
    "    def generate_sample_data(self, n_samples=1000):\n",
    "        \"\"\"Generate realistic healthcare service feedback data.\"\"\"\n",
    "        print(f\"\ud83d\udcca Generating {n_samples} sample healthcare feedback entries...\")\n",
    "        \n",
    "        services = [\n",
    "            \"Telemedicine Consultation\", \"Emergency Care\", \"Physical Therapy\",\n",
    "            \"Mental Health Counseling\", \"Pharmacy Services\", \"Laboratory Testing\",\n",
    "            \"Radiology Services\", \"Surgical Procedures\", \"Preventive Care\",\n",
    "            \"Specialist Consultation\", \"Home Healthcare\", \"Urgent Care\"\n",
    "        ]\n",
    "        \n",
    "        age_groups = [\"18-25\", \"26-35\", \"36-45\", \"46-55\", \"56-65\", \"65+\"]\n",
    "        genders = [\"Male\", \"Female\", \"Other\", \"Prefer not to say\"]\n",
    "        insurance_types = [\"Private\", \"Medicare\", \"Medicaid\", \"Uninsured\"]\n",
    "        \n",
    "        feedback_templates = {\n",
    "            \"positive\": [\n",
    "                \"The {service} was excellent. Staff was professional and caring.\",\n",
    "                \"Outstanding {service} experience. Highly recommend to others.\",\n",
    "                \"Very satisfied with {service}. Quick and efficient service.\",\n",
    "                \"The {service} team was knowledgeable and helpful throughout.\",\n",
    "                \"Exceptional {service} quality. Will definitely return.\",\n",
    "                \"Great experience with {service}. Everything went smoothly.\",\n",
    "                \"Amazing {service}. The staff was wonderful and caring.\",\n",
    "                \"Perfect {service} experience. Exceeded my expectations.\"\n",
    "            ],\n",
    "            \"negative\": [\n",
    "                \"Disappointed with {service}. Long wait times and poor communication.\",\n",
    "                \"The {service} experience was frustrating. Staff seemed overwhelmed.\",\n",
    "                \"Not satisfied with {service}. Expected better quality of care.\",\n",
    "                \"Poor {service} experience. Would not recommend to others.\",\n",
    "                \"The {service} was disappointing. Room for significant improvement.\",\n",
    "                \"Unsatisfactory {service}. Did not meet my expectations.\",\n",
    "                \"The {service} could be much better. Several issues encountered.\",\n",
    "                \"Below average {service}. Needs improvement in several areas.\"\n",
    "            ],\n",
    "            \"neutral\": [\n",
    "                \"The {service} was adequate. Met basic expectations.\",\n",
    "                \"Standard {service} experience. Nothing particularly notable.\",\n",
    "                \"The {service} was okay. Average quality overall.\",\n",
    "                \"Decent {service}. Met my basic needs.\",\n",
    "                \"The {service} was fine. Standard level of care.\",\n",
    "                \"Acceptable {service} experience. Met expectations.\",\n",
    "                \"The {service} was satisfactory. No major issues.\",\n",
    "                \"Average {service} experience. Standard quality.\"\n",
    "            ]\n",
    "        }\n",
    "        \n",
    "        data = []\n",
    "        random.seed(42)\n",
    "        \n",
    "        for i in range(n_samples):\n",
    "            service = random.choice(services)\n",
    "            sentiment_type = random.choices(\n",
    "                [\"positive\", \"negative\", \"neutral\"],\n",
    "                weights=[0.5, 0.3, 0.2]\n",
    "            )[0]\n",
    "            \n",
    "            # Generate feedback text\n",
    "            template = random.choice(feedback_templates[sentiment_type])\n",
    "            feedback_text = template.format(service=service)\n",
    "            \n",
    "            # Add service combinations (30% chance)\n",
    "            if random.random() < 0.3:\n",
    "                other_services = [s for s in services if s != service]\n",
    "                additional_service = random.choice(other_services)\n",
    "                combo_texts = [\n",
    "                    f\" Combined with {additional_service} - both were good.\",\n",
    "                    f\" Also used {additional_service} recently.\",\n",
    "                    f\" The {additional_service} service was also helpful.\",\n",
    "                    f\" Along with {additional_service}, the experience was positive.\"\n",
    "                ]\n",
    "                feedback_text += random.choice(combo_texts)\n",
    "            \n",
    "            # Generate rating based on sentiment\n",
    "            if sentiment_type == \"positive\":\n",
    "                rating = random.choices([4, 5], weights=[0.3, 0.7])[0]\n",
    "            elif sentiment_type == \"negative\":\n",
    "                rating = random.choices([1, 2], weights=[0.7, 0.3])[0]\n",
    "            else:\n",
    "                rating = random.choice([3, 4])\n",
    "            \n",
    "            # Generate date within last 6 months\n",
    "            days_ago = random.randint(1, 180)\n",
    "            date = datetime.now() - timedelta(days=days_ago)\n",
    "            \n",
    "            data.append({\n",
    "                \"id\": f\"FB_{i+1:04d}\",\n",
    "                \"service_type\": service,\n",
    "                \"feedback_text\": feedback_text,\n",
    "                \"rating\": rating,\n",
    "                \"date\": date,\n",
    "                \"age_group\": random.choice(age_groups),\n",
    "                \"gender\": random.choice(genders),\n",
    "                \"insurance_type\": random.choice(insurance_types),\n",
    "                \"has_combination\": \"Combined with\" in feedback_text or \"Also used\" in feedback_text\n",
    "            })\n",
    "        \n",
    "        self.data = pd.DataFrame(data)\n",
    "        print(f\"\u2705 Generated {len(self.data)} feedback entries\")\n",
    "        return self.data\n",
    "    \n",
    "    def analyze_sentiment(self):\n",
    "        \"\"\"Perform comprehensive sentiment analysis.\"\"\"\n",
    "        print(\"\ud83d\udd0d Performing sentiment analysis...\")\n",
    "        \n",
    "        # VADER sentiment analysis\n",
    "        sentiments = []\n",
    "        compound_scores = []\n",
    "        \n",
    "        for text in self.data[\"feedback_text\"]:\n",
    "            scores = self.sia.polarity_scores(text)\n",
    "            compound_scores.append(scores[\"compound\"])\n",
    "            \n",
    "            if scores[\"compound\"] >= 0.05:\n",
    "                sentiments.append(\"positive\")\n",
    "            elif scores[\"compound\"] <= -0.05:\n",
    "                sentiments.append(\"negative\")\n",
    "            else:\n",
    "                sentiments.append(\"neutral\")\n",
    "        \n",
    "        self.data[\"vader_sentiment\"] = sentiments\n",
    "        self.data[\"vader_compound\"] = compound_scores\n",
    "        \n",
    "        # TF-IDF clustering\n",
    "        self.tfidf_vectorizer = TfidfVectorizer(\n",
    "            max_features=1000,\n",
    "            stop_words=\"english\",\n",
    "            ngram_range=(1, 2)\n",
    "        )\n",
    "        \n",
    "        tfidf_matrix = self.tfidf_vectorizer.fit_transform(self.data[\"feedback_text\"])\n",
    "        \n",
    "        # Find optimal number of clusters\n",
    "        silhouette_scores = []\n",
    "        K_range = range(2, 11)\n",
    "        \n",
    "        for k in K_range:\n",
    "            kmeans = KMeans(n_clusters=k, random_state=42, n_init=10)\n",
    "            cluster_labels = kmeans.fit_predict(tfidf_matrix)\n",
    "            silhouette_avg = silhouette_score(tfidf_matrix, cluster_labels)\n",
    "            silhouette_scores.append(silhouette_avg)\n",
    "        \n",
    "        optimal_k = K_range[np.argmax(silhouette_scores)]\n",
    "        \n",
    "        # Final clustering\n",
    "        self.kmeans_model = KMeans(n_clusters=optimal_k, random_state=42, n_init=10)\n",
    "        clusters = self.kmeans_model.fit_predict(tfidf_matrix)\n",
    "        self.data[\"cluster\"] = clusters\n",
    "        \n",
    "        # LDA Topic Modeling\n",
    "        self.lda_model = LatentDirichletAllocation(\n",
    "            n_components=5,\n",
    "            random_state=42,\n",
    "            max_iter=10\n",
    "        )\n",
    "        \n",
    "        lda_topics = self.lda_model.fit_transform(tfidf_matrix)\n",
    "        dominant_topics = np.argmax(lda_topics, axis=1)\n",
    "        self.data[\"dominant_topic\"] = dominant_topics\n",
    "        \n",
    "        print(f\"\u2705 Sentiment analysis completed\")\n",
    "        print(f\"\ud83c\udfaf Optimal clusters: {optimal_k}\")\n",
    "        print(f\"\ud83d\udccb Topics discovered: 5\")\n",
    "        \n",
    "        self.analyzed_data = self.data.copy()\n",
    "        return self.analyzed_data\n",
    "    \n",
    "    def find_service_combinations(self):\n",
    "        \"\"\"Find and analyze service combinations.\"\"\"\n",
    "        print(\"\ud83d\udd17 Analyzing service combinations...\")\n",
    "        \n",
    "        combinations = []\n",
    "        \n",
    "        for idx, row in self.analyzed_data.iterrows():\n",
    "            text = row[\"feedback_text\"]\n",
    "            \n",
    "            # Look for service mentions\n",
    "            mentioned_services = []\n",
    "            services = [\n",
    "                \"Telemedicine Consultation\", \"Emergency Care\", \"Physical Therapy\",\n",
    "                \"Mental Health Counseling\", \"Pharmacy Services\", \"Laboratory Testing\",\n",
    "                \"Radiology Services\", \"Surgical Procedures\", \"Preventive Care\",\n",
    "                \"Specialist Consultation\", \"Home Healthcare\", \"Urgent Care\"\n",
    "            ]\n",
    "            \n",
    "            for service in services:\n",
    "                if service.lower() in text.lower():\n",
    "                    mentioned_services.append(service)\n",
    "            \n",
    "            # Check for combination language\n",
    "            has_combo_language = any(phrase in text.lower() for phrase in [\n",
    "                \"combined with\", \"also used\", \"along with\", \"in addition to\"\n",
    "            ])\n",
    "            \n",
    "            if len(mentioned_services) > 1 or has_combo_language:\n",
    "                combinations.append({\n",
    "                    \"id\": row[\"id\"],\n",
    "                    \"primary_service\": row[\"service_type\"],\n",
    "                    \"mentioned_services\": mentioned_services,\n",
    "                    \"sentiment\": row[\"vader_sentiment\"],\n",
    "                    \"sentiment_score\": row[\"vader_compound\"],\n",
    "                    \"feedback\": text,\n",
    "                    \"age_group\": row[\"age_group\"],\n",
    "                    \"gender\": row[\"gender\"],\n",
    "                    \"insurance_type\": row[\"insurance_type\"],\n",
    "                    \"rating\": row[\"rating\"]\n",
    "                })\n",
    "        \n",
    "        self.combinations = combinations\n",
    "        print(f\"\u2705 Found {len(combinations)} service combinations\")\n",
    "        return combinations\n",
    "    \n",
    "    def create_visualizations(self):\n",
    "        \"\"\"Create comprehensive visualizations.\"\"\"\n",
    "        print(\"\ud83d\udcc8 Creating visualizations...\")\n",
    "        \n",
    "        # Set up the plotting style\n",
    "        plt.style.use(\"default\")\n",
    "        fig = plt.figure(figsize=(20, 15))\n",
    "        \n",
    "        # 1. Sentiment Distribution\n",
    "        ax1 = plt.subplot(3, 4, 1)\n",
    "        sentiment_counts = self.analyzed_data[\"vader_sentiment\"].value_counts()\n",
    "        colors = [\"#2ecc71\", \"#e74c3c\", \"#f39c12\"]\n",
    "        ax1.pie(sentiment_counts.values, labels=sentiment_counts.index, autopct=\"%1.1f%%\",\n",
    "               colors=colors, startangle=90)\n",
    "        ax1.set_title(\"Sentiment Distribution\", fontsize=12, fontweight=\"bold\")\n",
    "        \n",
    "        # 2. Service Performance\n",
    "        ax2 = plt.subplot(3, 4, 2)\n",
    "        service_performance = self.analyzed_data.groupby(\"service_type\")[\"vader_compound\"].mean().sort_values(ascending=False)\n",
    "        top_services = service_performance.head(6)\n",
    "        bars = ax2.bar(range(len(top_services)), top_services.values, color=\"lightblue\", alpha=0.7)\n",
    "        ax2.set_title(\"Top Services by Sentiment\", fontsize=12, fontweight=\"bold\")\n",
    "        ax2.set_xticks(range(len(top_services)))\n",
    "        ax2.set_xticklabels(top_services.index, rotation=45, ha=\"right\")\n",
    "        ax2.grid(True, alpha=0.3)\n",
    "        \n",
    "        # 3. Rating vs Sentiment\n",
    "        ax3 = plt.subplot(3, 4, 3)\n",
    "        ax3.scatter(self.analyzed_data[\"rating\"], self.analyzed_data[\"vader_compound\"],\n",
    "                   alpha=0.6, color=\"purple\")\n",
    "        ax3.set_title(\"Rating vs Sentiment Score\", fontsize=12, fontweight=\"bold\")\n",
    "        ax3.set_xlabel(\"Rating\")\n",
    "        ax3.set_ylabel(\"Sentiment Score\")\n",
    "        ax3.grid(True, alpha=0.3)\n",
    "        \n",
    "        # 4. Service Combinations\n",
    "        ax4 = plt.subplot(3, 4, 4)\n",
    "        if self.combinations:\n",
    "            combo_sentiments = [c[\"sentiment\"] for c in self.combinations]\n",
    "            combo_counts = Counter(combo_sentiments)\n",
    "            bars = ax4.bar(combo_counts.keys(), combo_counts.values(),\n",
    "                          color=[\"#2ecc71\", \"#e74c3c\", \"#f39c12\"])\n",
    "            ax4.set_title(\"Service Combination Sentiment\", fontsize=12, fontweight=\"bold\")\n",
    "            ax4.set_ylabel(\"Count\")\n",
    "        else:\n",
    "            ax4.text(0.5, 0.5, \"No combinations\nfound\", ha=\"center\", va=\"center\",\n",
    "                    transform=ax4.transAxes, fontsize=12)\n",
    "            ax4.set_title(\"Service Combinations\", fontsize=12, fontweight=\"bold\")\n",
    "        \n",
    "        # 5. Age Group Analysis\n",
    "        ax5 = plt.subplot(3, 4, 5)\n",
    "        age_sentiment = self.analyzed_data.groupby(\"age_group\")[\"vader_compound\"].mean().sort_values(ascending=False)\n",
    "        bars = ax5.bar(range(len(age_sentiment)), age_sentiment.values, color=\"lightgreen\", alpha=0.7)\n",
    "        ax5.set_title(\"Sentiment by Age Group\", fontsize=12, fontweight=\"bold\")\n",
    "        ax5.set_xticks(range(len(age_sentiment)))\n",
    "        ax5.set_xticklabels(age_sentiment.index, rotation=45)\n",
    "        ax5.grid(True, alpha=0.3)\n",
    "        \n",
    "        # 6. Insurance Type Analysis\n",
    "        ax6 = plt.subplot(3, 4, 6)\n",
    "        insurance_sentiment = self.analyzed_data.groupby(\"insurance_type\")[\"vader_compound\"].mean().sort_values(ascending=False)\n",
    "        bars = ax6.bar(range(len(insurance_sentiment)), insurance_sentiment.values, color=\"lightcoral\", alpha=0.7)\n",
    "        ax6.set_title(\"Sentiment by Insurance\", fontsize=12, fontweight=\"bold\")\n",
    "        ax6.set_xticks(range(len(insurance_sentiment)))\n",
    "        ax6.set_xticklabels(insurance_sentiment.index, rotation=45)\n",
    "        ax6.grid(True, alpha=0.3)\n",
    "        \n",
    "        # 7. Temporal Trends\n",
    "        ax7 = plt.subplot(3, 4, 7)\n",
    "        self.analyzed_data[\"month\"] = self.analyzed_data[\"date\"].dt.to_period(\"M\")\n",
    "        monthly_sentiment = self.analyzed_data.groupby(\"month\")[\"vader_compound\"].mean()\n",
    "        ax7.plot(range(len(monthly_sentiment)), monthly_sentiment.values, marker=\"o\", color=\"green\", linewidth=2)\n",
    "        ax7.set_title(\"Monthly Sentiment Trend\", fontsize=12, fontweight=\"bold\")\n",
    "        ax7.set_xticks(range(len(monthly_sentiment)))\n",
    "        ax7.set_xticklabels([str(x) for x in monthly_sentiment.index], rotation=45)\n",
    "        ax7.grid(True, alpha=0.3)\n",
    "        \n",
    "        # 8. Cluster Analysis\n",
    "        ax8 = plt.subplot(3, 4, 8)\n",
    "        pca = PCA(n_components=2)\n",
    "        tfidf_matrix = self.tfidf_vectorizer.transform(self.analyzed_data[\"feedback_text\"])\n",
    "        tfidf_2d = pca.fit_transform(tfidf_matrix.toarray())\n",
    "        scatter = ax8.scatter(tfidf_2d[:, 0], tfidf_2d[:, 1], c=self.analyzed_data[\"cluster\"],\n",
    "                            cmap=\"viridis\", alpha=0.6)\n",
    "        ax8.set_title(\"Text Clusters\", fontsize=12, fontweight=\"bold\")\n",
    "        ax8.set_xlabel(\"PC1\")\n",
    "        ax8.set_ylabel(\"PC2\")\n",
    "        plt.colorbar(scatter, ax=ax8)\n",
    "        \n",
    "        # 9. Service Volume\n",
    "        ax9 = plt.subplot(3, 4, 9)\n",
    "        service_counts = self.analyzed_data[\"service_type\"].value_counts().head(8)\n",
    "        bars = ax9.barh(range(len(service_counts)), service_counts.values, color=\"lightblue\", alpha=0.7)\n",
    "        ax9.set_title(\"Service Volume\", fontsize=12, fontweight=\"bold\")\n",
    "        ax9.set_yticks(range(len(service_counts)))\n",
    "        ax9.set_yticklabels(service_counts.index)\n",
    "        ax9.grid(True, alpha=0.3)\n",
    "        \n",
    "        # 10. Sentiment Score Distribution\n",
    "        ax10 = plt.subplot(3, 4, 10)\n",
    "        ax10.hist(self.analyzed_data[\"vader_compound\"], bins=30, alpha=0.7, color=\"skyblue\", edgecolor=\"black\")\n",
    "        ax10.axvline(self.analyzed_data[\"vader_compound\"].mean(), color=\"red\", linestyle=\"--\",\n",
    "                    label=f\"Mean: {self.analyzed_data[\"vader_compound\"].mean():.3f}\")\n",
    "        ax10.set_title(\"Sentiment Score Distribution\", fontsize=12, fontweight=\"bold\")\n",
    "        ax10.set_xlabel(\"Sentiment Score\")\n",
    "        ax10.set_ylabel(\"Frequency\")\n",
    "        ax10.legend()\n",
    "        ax10.grid(True, alpha=0.3)\n",
    "        \n",
    "        # 11. Gender Analysis\n",
    "        ax11 = plt.subplot(3, 4, 11)\n",
    "        gender_sentiment = self.analyzed_data.groupby(\"gender\")[\"vader_compound\"].mean().sort_values(ascending=False)\n",
    "        bars = ax11.bar(range(len(gender_sentiment)), gender_sentiment.values, color=\"lightpink\", alpha=0.7)\n",
    "        ax11.set_title(\"Sentiment by Gender\", fontsize=12, fontweight=\"bold\")\n",
    "        ax11.set_xticks(range(len(gender_sentiment)))\n",
    "        ax11.set_xticklabels(gender_sentiment.index, rotation=45)\n",
    "        ax11.grid(True, alpha=0.3)\n",
    "        \n",
    "        # 12. Overall Summary\n",
    "        ax12 = plt.subplot(3, 4, 12)\n",
    "        ax12.axis(\"off\")\n",
    "        summary_text = f\"\"\"\n",
    "        \ud83d\udcca ANALYSIS SUMMARY\n",
    "        \n",
    "        Total Feedback: {len(self.analyzed_data):,}\n",
    "        Positive: {(self.analyzed_data[\"vader_sentiment\"] == \"positive\").sum()}\n",
    "        Negative: {(self.analyzed_data[\"vader_sentiment\"] == \"negative\").sum()}\n",
    "        Neutral: {(self.analyzed_data[\"vader_sentiment\"] == \"neutral\").sum()}\n",
    "        \n",
    "        Avg Sentiment: {self.analyzed_data[\"vader_compound\"].mean():.3f}\n",
    "        Service Types: {self.analyzed_data[\"service_type\"].nunique()}\n",
    "        Combinations: {len(self.combinations)}\n",
    "        Clusters: {self.analyzed_data[\"cluster\"].nunique()}\n",
    "        \"\"\"\n",
    "        ax12.text(0.1, 0.9, summary_text, transform=ax12.transAxes, fontsize=10,\n",
    "                verticalalignment=\"top\", fontfamily=\"monospace\")\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        print(\"\u2705 Visualizations completed!\")\n",
    "        return fig\n",
    "\n",
    "print(\"\u2705 Healthcare Sentiment Analyzer class loaded!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Initialize and Run Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the analyzer\n",
    "analyzer = HealthcareSentimentAnalyzer()\n",
    "\n",
    "# Generate sample data\n",
    "data = analyzer.generate_sample_data(1000)\n",
    "\n",
    "print(f\"\\n\ud83d\udcca Dataset Overview:\")\n",
    "print(f\"Total entries: {len(data):,}\")\n",
    "print(f\"Service types: {data[\"service_type\"].nunique()}\")\n",
    "print(f\"Date range: {data[\"date\"].min().date()} to {data[\"date\"].max().date()}\")\n",
    "\n",
    "# Show sample data\n",
    "print(\"\\n\ud83d\udccb Sample Data:\")\n",
    "display(data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run comprehensive sentiment analysis\n",
    "analyzed_data = analyzer.analyze_sentiment()\n",
    "\n",
    "# Find service combinations\n",
    "combinations = analyzer.find_service_combinations()\n",
    "\n",
    "print(f\"\\n\ud83d\udcc8 Analysis Results:\")\n",
    "print(f\"Sentiment distribution:\")\n",
    "print(analyzed_data[\"vader_sentiment\"].value_counts())\n",
    "print(f\"\\nAverage sentiment score: {analyzed_data[\"vader_compound\"].mean():.3f}\")\n",
    "print(f\"Service combinations found: {len(combinations)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Comprehensive Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create comprehensive visualizations\n",
    "fig = analyzer.create_visualizations()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. AI Assistant Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple AI Assistant for result interpretation\n",
    "class SimpleAIAssistant:\n",
    "    def __init__(self, analyzer):\n",
    "        self.analyzer = analyzer\n",
    "        self.prepare_context()\n",
    "    \n",
    "    def prepare_context(self):\n",
    "        self.context = {\n",
    "            \"total_feedback\": len(self.analyzer.analyzed_data),\n",
    "            \"sentiment_dist\": dict(self.analyzer.analyzed_data[\"vader_sentiment\"].value_counts()),\n",
    "            \"avg_sentiment\": self.analyzer.analyzed_data[\"vader_compound\"].mean(),\n",
    "            \"service_count\": self.analyzer.analyzed_data[\"service_type\"].nunique(),\n",
    "            \"combinations\": len(self.analyzer.combinations),\n",
    "            \"clusters\": self.analyzer.analyzed_data[\"cluster\"].nunique()\n",
    "        }\n",
    "    \n",
    "    def answer_question(self, question):\n",
    "        q = question.lower()\n",
    "        \n",
    "        if \"top\" in q and \"service\" in q:\n",
    "            top_services = self.analyzer.analyzed_data.groupby(\"service_type\")[\"vader_compound\"].mean().sort_values(ascending=False).head(3)\n",
    "            return f\"The top performing services are: {",
    ".join(top_services.index.tolist())}. These services show the highest average sentiment scores.\"\n",
    "        \n",
    "        elif \"combination\" in q:\n",
    "            if self.analyzer.combinations:\n",
    "                combo_df = pd.DataFrame(self.analyzer.combinations)\n",
    "                avg_combo_sentiment = combo_df[\"sentiment_score\"].mean()\n",
    "                return f\"Found {len(self.analyzer.combinations)} service combinations. Average sentiment for combinations: {avg_combo_sentiment:.3f}. This shows how patients feel when using multiple services together.\"\n",
    "            else:\n",
    "                return \"No service combinations were detected in the current dataset.\"\n",
    "        \n",
    "        elif \"sentiment\" in q:\n",
    "            pos_pct = (self.context[\"sentiment_dist\"][\"positive\"] / self.context[\"total_feedback\"]) * 100\n",
    "            return f\"Overall sentiment analysis shows {pos_pct:.1f}% positive feedback, with an average sentiment score of {self.context[\"avg_sentiment\"]:.3f}. This indicates generally positive patient experiences.\"\n",
    "        \n",
    "        elif \"recommendation\" in q:\n",
    "            return \"Key recommendations: 1) Focus on replicating success factors from top-performing services, 2) Address underperforming services with targeted improvements, 3) Monitor service combinations for cross-selling opportunities, 4) Implement regular sentiment monitoring.\"\n",
    "        \n",
    "        elif \"cluster\" in q:\n",
    "            return f\"Text clustering identified {self.context[\"clusters\"]} distinct groups of feedback, revealing natural patterns in patient experiences and common themes.\"\n",
    "        \n",
    "        else:\n",
    "            return f\"Based on the analysis of {self.context[\"total_feedback\"]} feedback entries across {self.context[\"service_count\"]} service types, the sentiment analysis reveals patterns in patient experiences. Ask a more specific question for detailed insights.\"\n",
    "\n",
    "print(\"\u2705 Simple AI Assistant class loaded!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize AI Assistant\n",
    "ai_assistant = SimpleAIAssistant(analyzer)\n",
    "\n",
    "print(\"\ud83e\udd16 AI Assistant ready! Ask questions about your analysis results.\")\n",
    "print(\"\\n\ud83d\udca1 Example questions you can ask:\")\n",
    "print(\"- What are the top performing services?\")\n",
    "print(\"- How do service combinations affect sentiment?\")\n",
    "print(\"- What insights can you provide about the sentiment analysis?\")\n",
    "print(\"- What recommendations do you have based on the results?\")\n",
    "print(\"- How do different demographic groups rate the services?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Interactive Q&A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interactive Q&A function\n",
    "def ask_question(question):\n",
    "    print(f\"\\n\u2753 Question: {question}\")\n",
    "    print(\"\ud83e\udd16 AI Assistant Response:\")\n",
    "    print(\"=\" * 50)\n",
    "    response = ai_assistant.answer_question(question)\n",
    "    print(response)\n",
    "    print(\"=\" * 50)\n",
    "    return response\n",
    "\n",
    "# Example questions\n",
    "ask_question(\"What are the top performing services based on sentiment analysis?\")\n",
    "ask_question(\"How do service combinations affect patient satisfaction?\")\n",
    "ask_question(\"What recommendations do you have for improving healthcare services?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Ask Your Own Questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ask your own question here!\n",
    "your_question = \"What insights can you provide about demographic patterns in the sentiment analysis?\"\n",
    "ask_question(your_question)\n",
    "\n",
    "# Try more questions:\n",
    "# ask_question(\"How do different age groups rate the services?\")\n",
    "# ask_question(\"What are the main themes identified in the feedback?\")\n",
    "# ask_question(\"How can we improve underperforming services?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \ud83c\udf89 Analysis Complete!\n",
    "\n",
    "### \u2705 What You've Accomplished:\n",
    "\n",
    "1. **Generated realistic healthcare feedback data** (1000 samples)\n",
    "2. **Performed comprehensive sentiment analysis** using VADER, clustering, and topic modeling\n",
    "3. **Analyzed service combinations** to understand cross-service patterns\n",
    "4. **Created rich visualizations** showing insights across multiple dimensions\n",
    "5. **Built an AI assistant** to interpret and explain results\n",
    "\n",
    "### \ud83d\ude80 Ready for Google Colab Sharing!\n",
    "\n",
    "This notebook is completely self-contained and ready to be shared. Simply:\n",
    "\n",
    "1. **Upload to Google Colab**\n",
    "2. **Run all cells** (Runtime \u2192 Run All)\n",
    "3. **Ask questions** using the AI assistant\n",
    "4. **Share with colleagues** for collaboration\n",
    "\n",
    "### \ud83d\udca1 Next Steps:\n",
    "\n",
    "- Replace synthetic data with your own healthcare feedback\n",
    "- Adjust analysis parameters for your specific needs\n",
    "- Export results for further analysis\n",
    "- Integrate with your existing healthcare systems\n",
    "\n",
    "**\ud83d\udd12 Note: This uses synthetic data for demonstration. For real healthcare data, ensure HIPAA compliance.**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "colab": {
   "provenance": [],
   "toc_visible": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}